{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c0fc97-03a1-4567-afc2-bc1c009f58ee",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:36px; font-weight:bold; color:#4A4A4A; background-color:#fff6e4; padding:10px; border:3px solid #f5ecda; border-radius:6px\">\n",
    "    Medical Cost Prediction\n",
    "    <p style=\"text-align:center; font-size:14px; font-weight:normal; color:#4A4A4A; margin-top:12px;\">\n",
    "        Author: Jens Bender <br> \n",
    "        Created: December 2025<br>\n",
    "        Last updated: January 2026\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb46ade-5325-4a6f-a876-a89fa84ff886",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Imports</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb71d4-23c3-4427-83da-a9f1b304504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data preprocessing (scikit-learn)\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform  # for random hyperparameter values\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_percentage_error, \n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ff7f1-cfe6-4266-9598-f8fa77825c29",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Data Loading and Inspection</h1>\n",
    "</div>\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Load the MEPS-HC 2023 data from the <code>h251.sas7bdat</code> file (SAS V9 format) into a Pandas DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566250d-933c-4ee9-950f-80f916b616b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load data using 'latin1' encoding because MEPS SAS files don't store text as UTF-8 and instead use Western European (ISO-8859-1), also known as latin1.\n",
    "    df = pd.read_sas(\"../data/h251.sas7bdat\", format=\"sas7bdat\", encoding=\"latin1\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: The file content could not be parsed.\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied when accessing the file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd5af1-3289-4fd7-8ccd-f9d9b49bc884",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> üìå Initial data inspection to understand the structure of the dataset and detect obvious issues.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723eebff-80f4-4e7e-9e94-6af8816a1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame info to check the number of rows and columns, data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a985d-3c7e-492f-9f34-a17df4f2c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top five rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06f785-b1fe-45ee-bfb2-224cb1235bf1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Data Preprocessing</h1>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è <strong>Note:</strong> Kept column names in ALL CAPS to ensure consistency with official <b><a href=\"../docs/references/h251doc.pdf\">MEPS documentation</a></b>, <b><a href=\"../docs/references/h251cb.pdf\">codebook</a></b>, and <b><a href=\"../docs/references/data_dictionary.md\">data dictionary</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5bc54-6ee9-4419-8811-86799d1874f0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Handling Duplicates</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Identify duplicates based on:\n",
    "<ul>\n",
    "    <li><strong>All columns</strong>: To detect exactly identical rows.</li>\n",
    "    <li><strong>ID column only</strong>: To ensure that no two people share the same ID.</li>\n",
    "    <li><strong>All columns except ID</strong>: To catch \"hidden\" duplicates where the same respondent may have been recorded twice under different IDs.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6bf46-8cf6-4991-bea4-c2b167ff91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on all columns\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f382f-e7d9-46c3-b43a-5e6b5f8eb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on the ID column\n",
    "df.duplicated([\"DUPERSID\"]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07847cb-f83b-405f-b585-24f953c1cb6b",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ‚úÖ No duplicates were found based on all columns or the ID column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on all columns except ID columns\n",
    "id_columns = [\"DUPERSID\", \"DUID\", \"PID\", \"PANEL\"]\n",
    "duplicates_without_id = df.duplicated(subset=df.columns.drop(id_columns), keep=False)\n",
    "duplicates_without_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360131b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show duplicates\n",
    "df[duplicates_without_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a4d05-0800-486e-9802-7b438182e952",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> Detected 3 pairs (6 rows) of  duplicates based on all columns except ID columns. \n",
    "    <p style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        These respondents have identical values across all 1,300+ columns except for their IDs. They appear to be young siblings (ages 1 and 5) from the same household with identical parent-reported health data, sample weights, and costs. Analysis suggests they are valid respondents rather than \"ghost\" records. Regardless, they will be excluded when filtering for the adult target population.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19272d24-c56d-4a19-9ffc-dfd82d02fff1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Variable Selection</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Filter the following 29 columns (out of 1,374):\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>ID:</b> Unique identifier for each respondent (<code>DUPERSID</code>).</li>\n",
    "        <li><b>Sample Weights:</b> Ensures population representativeness (<code>PERWT23F</code>).</li>\n",
    "        <li><b>Candidate Features:</b> 26 variables selected for their consumer accessibility, beginning-of-year measurement, and predictive power.</li> \n",
    "        <li><b>Target Variable:</b> Total out-of-pocket health care costs (<code>TOTSLF23</code>).</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <b>Rationale:</b> For a detailed breakdown of the target variable selection and feature selection criteria, see the <b><a href=\"../docs/specs/technical_specifications.md\">Technical Specifications</a></b> and <b><a href=\"../docs/research/candidate_features.md\">Candidate Features Research</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep \n",
    "columns_to_keep = [\n",
    "    # 1. ID\n",
    "    \"DUPERSID\",\n",
    "    \n",
    "    # 2. Sample Weights\n",
    "    \"PERWT23F\", \n",
    "\n",
    "    # 3 Candidate Features.\n",
    "    # 3.1 Demographics\n",
    "    \"AGE23X\", \"SEX\", \"REGION23\", \"MARRY31X\",\n",
    "    \n",
    "    # 3.2 Socioeconomic\n",
    "    \"POVCAT23\", \"FAMSZE23\", \"HIDEG\", \"EMPST31\",\n",
    "    \n",
    "    # 3.3 Insurance & Access\n",
    "    \"INSCOV23\", \"HAVEUS42\",\n",
    "    \n",
    "    # 3.4 Perceived Health & Lifestyle\n",
    "    \"RTHLTH31\", \"MNHLTH31\", \"ADSMOK42\",\n",
    "    \n",
    "    # 3.5 Limitations & Symptoms\n",
    "    \"ADLHLP31\", \"IADLHP31\", \"WLKLIM31\", \"COGLIM31\", \"JTPAIN31_M18\",\n",
    "    \n",
    "    # 3.6 Chronic Conditions\n",
    "    \"HIBPDX\", \"CHOLDX\", \"DIABDX_M18\", \"CHDDX\", \"STRKDX\", \"CANCERDX\", \"ARTHDX\", \"ASTHDX\", \n",
    "    \n",
    "    # 4. Healthcare Expenditure (Target)\n",
    "    \"TOTSLF23\"\n",
    "]\n",
    "\n",
    "# Drop all other columns (keeping 29 out of 1,374)\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab17d4-5459-46b5-b864-3e992c45e4c8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Target Population Filtering</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Filter rows to match the target population (target audience for app) based on the following criteria:\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>Positive person weight (<code>PERWT23F > 0</code>):</b> Drop respondents with a person weight of zero (i.e., 456 respondents). These individuals are considered \"out-of-scope\" for the full-year population (e.g., they joined the military, were institutionalized, or moved abroad).</li>\n",
    "        <li><b>Adults (<code>AGE23X >= 18</code>):</b> Drop respondents under age 18 (i.e., 3796 respondents), as the medical cost planner app targets adults.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <b>Note:</b> Keeps 14,768 out of 18,919 respondents.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80beb46-f9cf-4fc3-a80e-dee328f07f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame \n",
    "df = df[(df[\"PERWT23F\"] > 0) & (df[\"AGE23X\"] >= 18)].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1bd90-9e04-432f-bb46-ef10b0530f31",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Handling Data Types</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Identify and convert incorrect storage data types.\n",
    "    <ul>\n",
    "        <li><b>ID:</b> <code>DUPERSID</code> is an identifier, not a quantity. Converting them to <code>string</code> prevents unintended math.</li>\n",
    "        <li><b>Sample Weights:</b> <code>PERWT23F</code> contains decimal precision critical for population-level estimates. Must remain <code>float</code>.</li>\n",
    "        <li><b>Candidate Features:</b> The SAS loader stored all 26 features as floats by default. Although many features are categorical and represent integer codes (e.g., 1=Male, 2=Female), they are maintained as <code>float</code> for three practical reasons:\n",
    "            <ul>\n",
    "                <li>Missing Value Compatibility: In standard Pandas, <code>np.nan</code> is a floating-point object. Assigning it to an integer column automatically casts back to <code>float64</code>.</li>\n",
    "                <li>Data Preprocessing Consistency: scikit-learn transformers (e.g., <code>SimpleImputer</code>, <code>StandardScaler</code>) internally use floats and automatically convert numerical inputs to <code>float</code>, even when using <code>set_config(transform_output=\"pandas\")</code>. Keeping them as floats avoids redundant type casting.</li>\n",
    "                <li>Model Consistency: Most machine learning models (e.g., XGBoost, Linear Regression) internally use floats and automatically convert numerical inputs to <code>float</code> during training and inference. Keeping them as floats avoids redundant type casting.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>Target Variable:</b> <code>TOTSLF23</code> was stored as <code>float</code> by the SAS loader. Although it is rounded to whole dollars in the MEPS data, it is kept as <code>float</code> for data preprocessing and model consistency and to avoid redundant type casting, as ML models deliver <code>float</code> predictions during training and inference.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b59357-2082-44a7-9862-589ccd104e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify storage data types (defaulted to float/object by SAS loader)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ID to string\n",
    "df[\"DUPERSID\"] = df[\"DUPERSID\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c1c55-f1a7-4322-8f2b-d0e4475d767d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Standardizing Missing Values</h1>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è <b>Pandas Missing Value Types</b>:\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>np.nan:</b> Standard missing value indicator (technically a float); often the default in Pandas for numerical data.</li>\n",
    "        <li><b>pd.NA:</b> Unified missing value indicator for modern nullable data types (mostly integer and boolean).</li>\n",
    "        <li><b>None:</b> Python's native type; often used for object and string data.</li>\n",
    "        <li><b>pd.NaT:</b> For datetime and timedelta data types.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <b>MEPS Missing Value Codes:</b>\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>-1 INAPPLICABLE:</b> Variable does not apply (structural skip).</li>\n",
    "        <li><b>-7 REFUSED:</b> Person refused to answer.</li>\n",
    "        <li><b>-8 DON'T KNOW:</b> Person did not know the answer.</li>\n",
    "        <li><b>-9 NOT ASCERTAINED:</b> Administrative or technical error in collection.</li>\n",
    "        <li><b>-15 CANNOT BE COMPUTED:</b> Incomplete data for a constructed variable.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf771bde-99a8-4618-8c2d-82de58a9a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Pandas missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fd4f1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå <b>Handle MEPS-Specific Missing Values and Skip Patterns</b>\n",
    "    <br><br>\n",
    "    <b>Understanding Skip Patterns</b><br>\n",
    "    Skip patterns (routing logic) are used in surveys to ensure respondents only answer questions relevant to them, reducing burden and improving data quality. For analysis, this creates \"structural\" missingness (coded as -1 Inapplicable) can often be recovered by looking at the respondent's path through the survey.\n",
    "    <br><br>\n",
    "    <b>Recovering Implied Values:</b>  \n",
    "    <ul>\n",
    "        <li><b>Smoker (<code>ADSMOK42</code>):</b> This question is only asked if the respondent already confirmed smoking 100+ cigarettes in their life. Those who said \"No\" skip this and are coded -1. In this project, these \"Never Smokers\" are mapped to \"No\" (2).</li>\n",
    "        <li><b>Joint Pain (<code>JTPAIN31_M18</code>):</b> Respondents who already reported an arthritis diagnosis (<code>ARTHDX = 1</code>) earlier in the interview skip this question and are coded -1. Since arthritis inherently involves joint symptoms, these values are mapped to \"Yes\" (1).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover implied values\n",
    "# Smoker: Convert -1 (Never Smoker) to 2 (No)\n",
    "df.loc[df[\"ADSMOK42\"] == -1, \"ADSMOK42\"] = 2\n",
    "\n",
    "# Joint Pain: Convert -1 to 1 (Yes) only if they have Arthritis \n",
    "df.loc[(df[\"JTPAIN31_M18\"] == -1) & (df[\"ARTHDX\"] == 1), \"JTPAIN31_M18\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45ca1e-7a62-4ee5-9815-47a528cae451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify MEPS missing values \n",
    "missing_codes = [-1, -7, -8, -9, -15]\n",
    "missing_frequency_df = pd.DataFrame({code: (df == code).sum() for code in missing_codes})\n",
    "missing_frequency_df[\"TOTAL\"] = missing_frequency_df.sum(axis=1)\n",
    "missing_frequency_df[\"PERCENTAGE\"] = (missing_frequency_df[\"TOTAL\"] / len(df) * 100).round(2)\n",
    "missing_frequency_df.sort_values(\"TOTAL\", ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82708ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all MEPS missing codes to np.nan\n",
    "df = df.replace(missing_codes, np.nan)\n",
    "\n",
    "# Verify results\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2413d70-ad80-4f97-af40-0f1e56a10b78",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Train-Validation-Test Split</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "    üìå Split the data into 80% for training, 10% for validation, and 10% for testing.\n",
    "    <table style=\"margin-left:0; margin-top:20px; margin-bottom:20px\">\n",
    "        <tr>\n",
    "            <th style=\"background-color:#f5ecda;\">Data</th>\n",
    "            <th style=\"background-color:#f5ecda;\">Size (%)</th>\n",
    "            <th style=\"background-color:#f5ecda;\">Size (Total)</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#fff6e4;\">Training Set</td>\n",
    "            <td style=\"background-color:#fff6e4;\">80%</td>\n",
    "            <td style=\"background-color:#fff6e4;\">11,814</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#f5ecda;\">Validation Set</td>\n",
    "            <td style=\"background-color:#f5ecda;\">10%</td>\n",
    "            <td style=\"background-color:#f5ecda;\">1,477</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#fff6e4;\">Test Set</td>\n",
    "            <td style=\"background-color:#fff6e4;\">10%</td>\n",
    "            <td style=\"background-color:#fff6e4;\">1,477</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43bb6b-9495-40b6-9361-c679fbbf7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X features and y target\n",
    "X = df.drop(\"TOTSLF23\", axis=1)\n",
    "y = df[\"TOTSLF23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b09251-1df0-4598-9da1-70ae4d6307bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and temporary sets (80% train, 20% temporary)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary data into validation and test sets (50% each)\n",
    "# Note: This accomplishes a 80% training, 10% validation and 10% test set size\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Delete the temporary data to free up memory\n",
    "del X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c355c2-6e31-44b4-942a-9809fa990ded",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Exploratory Data Analysis (EDA)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ede20-f3f6-4774-8c25-54b6feb8333e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Univariate EDA</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è Analyze the distribution of a single column using descriptive statistics and visualizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e08b38-c905-4f2f-9cc1-b9eddac2a5da",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4e8ac8; color:white; padding:10px; border-radius:6px;\">\n",
    "    <h3 style=\"margin:0px\">Sample Weights</h3>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Examine descriptive statistics and visualize the distribution of the sample weights. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6a8c48-ef92-43c9-945a-0c6fb4317910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of sample weights\n",
    "df[\"PERWT23F\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607693e7-1135-458c-b3ba-71f1713bf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of sample weights\n",
    "df[\"PERWT23F\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c166f-877a-46d2-b039-4381c4ba4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of sample weights\n",
    "sns.histplot(df[\"PERWT23F\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba6e20d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> Using sample weights in machine learning models is essential to correct for oversampling and ensure that predictions are representative of the U.S. civilian noninstitutionalized adult population. \n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>Sum:</b> The sum of all weights is approximately 260 million, representing the estimated U.S. adult population in 2023.</li>\n",
    "        <li><b>Median:</b> A typical respondent represents roughly 14,600 people.</li>\n",
    "        <li><b>Right-Skewed Distribution:</b> The mean (17,584) is higher than the median, confirming that a small number of respondents represent a disproportionately large share of the population.</li>\n",
    "        <li><b>Sampling Strategy:</b> Weights range from 502 to 131,657. This reflects MEPS's strategy of oversampling specific subgroups to ensure reliable estimates for minority or high-need populations.</li>\n",
    "        <li><b>Bias Correction:</b> Because weights vary significantly (std ‚âà 12,334), unweighted models or averages would be biased. Using <code>sample_weight</code> during training ensures the model's loss function prioritizes population representativeness.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccbccf-4f44-4781-bbd3-702244b2b93a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4e8ac8; color:white; padding:10px; border-radius:6px;\">\n",
    "    <h3 style=\"margin:0px\">Target Variable</h3>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è Examine descriptive statistics and visualize the distribution of total out-of-pocket health care costs.\n",
    "    <br>\n",
    "    <b>Note:</b> Unless otherwise specified, all descriptive statistics and insights in this section refer to population-level estimates (calculated using sample weights) to ensure representativeness of the U.S. adult population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc6827-8945-406c-87e1-9c87b9273d40",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Descriptive Statistics</strong> <br>\n",
    "    üìå Examine descriptive statistics of total out-of-pocket health care costs, both on sample-level and population-level. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0b48d-11c1-4e0a-ba37-43aa93f08548",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Helper function to calculate weighted quantiles (using numpy; not available in pandas)\n",
    "def weighted_quantile(variable, weights, quantile):\n",
    "    sorter = np.argsort(variable)\n",
    "    values = variable.iloc[sorter]\n",
    "    weights = weights.iloc[sorter]\n",
    "    cumulative_weight = np.cumsum(weights) - 0.5 * weights\n",
    "    cumulative_weight /= np.sum(weights)\n",
    "    return np.interp(quantile, cumulative_weight, values)\n",
    "\n",
    "# Helper function to calculate weighted standard deviation (using numpy; not available in pandas)\n",
    "def weighted_std(variable, weights):\n",
    "    weighted_mean = np.average(variable, weights=weights)\n",
    "    weighted_variance = np.average((variable - weighted_mean)**2, weights=weights)\n",
    "    return np.sqrt(weighted_variance)\n",
    "\n",
    "# Calculate weighted (population) statistics\n",
    "pop_mean = np.average(df[\"TOTSLF23\"], weights=df[\"PERWT23F\"])\n",
    "pop_std = weighted_std(df[\"TOTSLF23\"], weights=df[\"PERWT23F\"])\n",
    "pop_p25 = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], 0.25)\n",
    "pop_median = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], 0.5)\n",
    "pop_p75 = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], 0.75)\n",
    "pop_p99 = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], 0.99)\n",
    "pop_p999 = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], 0.999)\n",
    "\n",
    "# Calculate sample (unweighted) quantiles\n",
    "sample_p99 = df[\"TOTSLF23\"].quantile(0.99)\n",
    "sample_p999 = df[\"TOTSLF23\"].quantile(0.999)\n",
    "\n",
    "# Calculate total costs (sum)\n",
    "sample_total_costs = df[\"TOTSLF23\"].sum()\n",
    "df[\"pop_costs\"] = df[\"TOTSLF23\"] * df[\"PERWT23F\"]  \n",
    "pop_total_costs = df[\"pop_costs\"].sum()\n",
    "\n",
    "# Create comparison table: Sample vs. population statistics \n",
    "sample_vs_population_stats = pd.DataFrame({\n",
    "    \"Sample (Unweighted)\": [\n",
    "        len(df),\n",
    "        df[\"TOTSLF23\"].mean(),\n",
    "        df[\"TOTSLF23\"].std(),\n",
    "        df[\"TOTSLF23\"].min(),\n",
    "        df[\"TOTSLF23\"].quantile(0.25),\n",
    "        df[\"TOTSLF23\"].median(),\n",
    "        df[\"TOTSLF23\"].quantile(0.75),\n",
    "        sample_p99,\n",
    "        sample_p999,\n",
    "        df[\"TOTSLF23\"].max(),\n",
    "        sample_total_costs\n",
    "    ],\n",
    "    \"Population (Weighted)\": [\n",
    "        df[\"PERWT23F\"].sum(),  # sum of weights = count of target population\n",
    "        pop_mean,\n",
    "        pop_std,\n",
    "        df[\"TOTSLF23\"].min(),  # min is identical\n",
    "        pop_p25,\n",
    "        pop_median,\n",
    "        pop_p75,\n",
    "        pop_p99,\n",
    "        pop_p999,\n",
    "        df[\"TOTSLF23\"].max(),  # max is identical\n",
    "        pop_total_costs\n",
    "    ]\n",
    "}, index=[\"count\", \"mean\", \"std\", \"min\", \"25%\", \"50%\", \"75%\", \"99%\", \"99.9%\", \"max\", \"sum\"])\n",
    "\n",
    "# Display table\n",
    "# Formatting: Comma thousand separator and rounded to zero decimals (sample sum in Millions, population sum in Billions with one decimal)\n",
    "sample_vs_population_stats.style.format(\"{:,.0f}\") \\\n",
    "    .format(lambda x: f\"${x/1e6:.1f}M\", subset=(\"sum\", \"Sample (Unweighted)\")) \\\n",
    "    .format(lambda x: f\"${x/1e9:.1f}B\", subset=(\"sum\", \"Population (Weighted)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e499a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> The descriptive statistics reveal a highly skewed and volatile cost distribution, emphasizing the importance of using sample weights for representative estimates.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>Right Skewness:</b> The population mean (\\$1,106) is over 4x higher than the median (\\$251), indicating that a few high-cost cases disproportionately influence the average.</li>\n",
    "        <li><b>Sampling Bias Correction:</b> Weighted population statistics are consistently lower than unweighted sample statistics (e.g., mean drops from \\$1,160 to \\$1,106), showing that the raw sample slightly over-represented higher-cost individuals.</li>\n",
    "        <li><b>Extreme Financial Risk:</b> While 75% of the population spends less than \\$1,042 out-of-pocket, the maximum reaches \\$104,652, highlighting severe financial exposure for a minority.</li>\n",
    "        <li><b>High Dispersion:</b> The standard deviation (~\\$3,000) is nearly triple the mean, reflecting the inherent unpredictability and high variance in health care costs.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54d1bc-fca3-4581-bdb5-767b1c70117d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Histogram</strong> <br> \n",
    "    üìå Visualize the distribution of out-of-pocket health care costs. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e16737-bf84-4a7d-96b8-e8a3f13ed064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram: Sample vs. Population (overlayed)\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    data=df, x=\"TOTSLF23\", label=\"Sample (Unweighted)\",\n",
    "    stat=\"probability\", bins=50, color=\"#2c699d\", alpha=0.4, element=\"step\"\n",
    ")\n",
    "\n",
    "sns.histplot(\n",
    "    data=df, x=\"TOTSLF23\", weights=\"PERWT23F\", label=\"Population (Weighted)\",\n",
    "    stat=\"probability\", bins=50, color=\"#4e8ac8\", alpha=0.6, element=\"step\"\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Full Distribution of Out-of-Pocket Costs\")\n",
    "plt.xlabel(\"Out-of-Pocket Costs ($)\")\n",
    "plt.ylabel(\"Population Share\")\n",
    "plt.legend()\n",
    "\n",
    "# Format X-axis as currency with commas\n",
    "plt.gca().xaxis.set_major_formatter(mtick.StrMethodFormatter(\"${x:,.0f}\"))\n",
    "# Format Y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c86f99",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è Note: Due to the zero-inflation (22% at \\$0) and the extremely heavy tail (max \\$104k), the full distribution is heavily compressed into the first few bins.<br>\n",
    "    üìå Visualize the \"typical\" distribution excluding zeros and the top 1% of spenders. This means zooming in a bit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of typical range (0 < Costs <= 99th Percentile)\n",
    "plot_data = df[(df[\"TOTSLF23\"] > 0) & (df[\"TOTSLF23\"] <= pop_p99)].copy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(\n",
    "    data=plot_data, x=\"TOTSLF23\", label=\"Sample (Unweighted)\",\n",
    "    stat=\"probability\", bins=50, color=\"#2c699d\", alpha=0.4, element=\"step\"\n",
    ")\n",
    "\n",
    "sns.histplot(\n",
    "    data=plot_data, x=\"TOTSLF23\", weights=\"PERWT23F\", label=\"Population (Weighted)\",\n",
    "    stat=\"probability\", bins=50, color=\"#4e8ac8\", alpha=0.6, element=\"step\"\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "plt.title(\"Distribution of Typical Out-of-Pocket Costs (0 < Costs \\u2264 99th Percentile)\")\n",
    "plt.xlabel(\"Out-of-Pocket Costs ($)\")\n",
    "plt.ylabel(\"Population Share\")\n",
    "plt.legend()\n",
    "\n",
    "# Format X-axis as currency with commas\n",
    "plt.gca().xaxis.set_major_formatter(mtick.StrMethodFormatter(\"${x:,.0f}\"))\n",
    "# Format Y-axis as percentages\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a197c-f752-447f-a8e2-83a4291bb667",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Zero Costs Analysis</strong> <br>\n",
    "    üìå Deeper analysis of people with zero out-of-pocket health care costs (sample and population). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9427d8e-502b-4502-9f54-640ea64f1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero costs analysis\n",
    "zero_costs_df = pd.DataFrame({\n",
    "    \"Sample (Unweighted) Count\": [len(df[df[\"TOTSLF23\"] == 0]), len(df[df[\"TOTSLF23\"] > 0])],\n",
    "    \"Population (Weighted) Count\": [df[df[\"TOTSLF23\"] == 0][\"PERWT23F\"].sum(), df[df[\"TOTSLF23\"] > 0][\"PERWT23F\"].sum()],\n",
    "    \"Sample (Unweighted) %\": [\n",
    "        (df[\"TOTSLF23\"] == 0).mean() * 100,\n",
    "        (df[\"TOTSLF23\"] > 0).mean() * 100\n",
    "    ],\n",
    "    \"Population (Weighted) %\": [\n",
    "        (df.loc[df[\"TOTSLF23\"] == 0, \"PERWT23F\"].sum() / df[\"PERWT23F\"].sum()) * 100,\n",
    "        (df.loc[df[\"TOTSLF23\"] > 0, \"PERWT23F\"].sum() / df[\"PERWT23F\"].sum()) * 100\n",
    "    ]\n",
    "}, index=[\"Zero Costs\", \"Positive Costs\"]).round(2)\n",
    "\n",
    "zero_costs_df.style.format({\n",
    "    \"Sample (Unweighted) Count\": \"{:,.0f}\",\n",
    "    \"Population (Weighted) Count\": \"{:,.0f}\",\n",
    "    \"Sample (Unweighted) %\": \"{:.1f}%\",\n",
    "    \"Population (Weighted) %\": \"{:.1f}%\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729385a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> The large proportion of zeros confirms that the target variable is zero-inflated.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>High Zero-Cost Prevalence:</b> Over 22% of the U.S. adult population (approx. 58 million people) had zero out-of-pocket health care costs in 2023.</li>\n",
    "        <li><b>Correction of Sampling Bias:</b> The weighted population percentage (22.3%) is higher than the unweighted sample percentage (20.7%), indicating that zero-cost individuals were slightly under-represented in the raw survey data.</li>\n",
    "        <li><b>Modeling Implications:</b> The zero-inflated target variable suggests that a two-part modeling strategy (e.g., predicting the probability of any spend vs. the amount of spend) may be more effective than a single standard regression.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c8d3bb-dc36-47d7-b95c-8358b37a2ec4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Top 1% Analysis</strong> <br>\n",
    "    üìå Deeper analysis of respondents in the top 1% and top 0.1% of out-of-pocket health care costs to understand extreme tail risk. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b218849-3849-4c3d-9f24-cc07d5615a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1% analysis\n",
    "# Sample (Unweighted)\n",
    "sample_top_1_costs = df[df[\"TOTSLF23\"] >= sample_p99][\"TOTSLF23\"].sum()\n",
    "sample_top_01_costs = df[df[\"TOTSLF23\"] >= sample_p999][\"TOTSLF23\"].sum()\n",
    "\n",
    "# Population (Weighted)\n",
    "pop_top_1_costs = df[df[\"TOTSLF23\"] >= pop_p99][\"pop_costs\"].sum()\n",
    "pop_top_01_costs = df[df[\"TOTSLF23\"] >= pop_p999][\"pop_costs\"].sum()\n",
    "\n",
    "# Create comparison table\n",
    "top_1_df = pd.DataFrame({\n",
    "    \"Sample (Unweighted)\": [\n",
    "        sample_p99,\n",
    "        sample_top_1_costs / 1e6,  # Millions\n",
    "        (sample_top_1_costs / sample_total_costs) * 100,\n",
    "        sample_p999,\n",
    "        sample_top_01_costs / 1e6,  # Millions\n",
    "        (sample_top_01_costs / sample_total_costs) * 100\n",
    "    ],\n",
    "    \"Population (Weighted)\": [\n",
    "        pop_p99,\n",
    "        pop_top_1_costs / 1e9,  # Billions\n",
    "        (pop_top_1_costs / pop_total_costs) * 100,\n",
    "        pop_p999,\n",
    "        pop_top_01_costs / 1e9,  # Billions\n",
    "        (pop_top_01_costs / pop_total_costs) * 100\n",
    "    ]\n",
    "}, index=[\n",
    "    \"Top 1% Threshold\",\n",
    "    \"Top 1% Total Costs\",\n",
    "    \"Top 1% Share of Costs\",\n",
    "    \"Top 0.1% Threshold\",\n",
    "    \"Top 0.1% Total Costs\",\n",
    "    \"Top 0.1% Share of Costs\"\n",
    "])\n",
    "\n",
    "# Style the table\n",
    "top_1_df.style.format(\"${:,.0f}\", subset=([\"Top 0.1% Threshold\", \"Top 1% Threshold\"], slice(None))) \\\n",
    "                 .format(\"${:,.1f}M\", subset=([\"Top 0.1% Total Costs\", \"Top 1% Total Costs\"], \"Sample (Unweighted)\")) \\\n",
    "                 .format(\"${:,.1f}B\", subset=([\"Top 0.1% Total Costs\", \"Top 1% Total Costs\"], \"Population (Weighted)\")) \\\n",
    "                 .format(\"{:.1f}%\", subset=([\"Top 0.1% Share of Costs\", \"Top 1% Share of Costs\"], slice(None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa0c7a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> Extreme cost concentration in the tail of the distribution.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>The 1% Rule:</b> The top 1% of spenders ‚Äîthose spending over ~\\$13k‚Äîaccount for roughly 20% of all out-of-pocket costs.</li>\n",
    "        <li><b>The Hyper-Tail (Top 0.1%):</b> The top 0.1% of spenders‚Äîthose spending over ~\\$39k‚Äîaccount for a disproportionate share of total costs (approx. 5%). This highlights that the tail is not just long, but extremely heavy.</li>\n",
    "        <li><b>Extreme Outliers:</b> The gap between the 99th percentile (\\$12,868) and the maximum (\\$104,652) is massive. These \"super-spenders\" represent a significant challenge for predictive modeling, as a single misprediction here could lead to very high error (RMSE).</li>\n",
    "        <li><b>Financial Risk Benchmarks:</b> These thresholds provide a clear picture of what \"catastrophic\" spending looks like in the U.S. adult population.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the \"Super-Spenders\" (Everyone in the Top 0.1% of the population)\n",
    "# This helps us identify if there are common patterns (e.g., age or chronic conditions) among extreme spenders.\n",
    "chronic_cols = [\"HIBPDX\", \"CHOLDX\", \"DIABDX_M18\", \"CHDDX\", \"STRKDX\", \"CANCERDX\", \"ARTHDX\", \"ASTHDX\"]\n",
    "df[\"CHRONIC_COUNT\"] = (df[chronic_cols] == 1).sum(axis=1)\n",
    "\n",
    "super_spenders = df[df[\"TOTSLF23\"] >= pop_p999].sort_values(\"TOTSLF23\", ascending=False)\n",
    "super_spenders[[\"TOTSLF23\", \"PERWT23F\", \"AGE23X\", \"SEX\", \"INSCOV23\", \"CHRONIC_COUNT\"] + chronic_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d5f2a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> The \"Super-Spender\" profiles reveal a critical dichotomy for predictive modeling.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>Acute vs. Chronic Drivers:</b> We see two distinct profiles: \"Multi-Morbid\" elderly (e.g., 85yo with 7 conditions) and \"Acute Shock\" individuals (young with 0-1 conditions). This suggests that while chronic disease predicts higher costs on average, the extreme tail is often driven by unpredictable acute events (accidents, rare surgeries).</li>\n",
    "        <li><b>The \"Black Swan\":</b> The absolute maximum outlier is a 24-year-old with only 1 chronic condition but ~\\$104k in out-of-pocket costs. With a high sample weight (~31k), this single respondent represents over 30,000 people. This is a \"Black Swan\" event‚Äîatypical and unpredictable‚Äîthat could severely impair model performance if not handled carefully. Mathematically, because RMSE squares the error, a single \\$50,000 prediction error on the top outlier adds as much to the loss function as \\$1,500 errors on 1,000 different people. The model will be naturally \"obsessed\" with fitting these few outliers at the expense of the general population.</li>\n",
    "        <li><b>The Insurance Paradox:</b> Surprisingly, only one of the top 15 spenders is uninsured (<code>INSCOV23=3</code>). Most even have private insurance (n=11). This shows that high out-of-pocket costs in the U.S. are not just a problem for the uninsured, but often hit those with coverage who face high deductibles, co-pays, or non-covered services.</li>\n",
    "        <li><b>Strategy:</b> To prevent these outliers from dominating the training, we must consider target transformations (Log/Box-Cox) or robust regression techniques that \"downweight\" the influence of extreme residuals.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3aa8ba",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Cost Concentration Analysis</strong> <br>\n",
    "    üìå Examine the cost thresholds, totals, and shares for the top 1%, 5%, 10%, 20%, and 50% of spenders (sample and population). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Concentration Benchmarks \n",
    "percentiles = [0.99, 0.95, 0.9, 0.8, 0.5]\n",
    "stats = []\n",
    "\n",
    "sample_total_costs = df[\"TOTSLF23\"].sum()\n",
    "pop_total_costs = df[\"pop_costs\"].sum()\n",
    "\n",
    "for p in percentiles:\n",
    "    # Calculate Thresholds\n",
    "    sample_threshold = df[\"TOTSLF23\"].quantile(p)\n",
    "    pop_threshold = weighted_quantile(df[\"TOTSLF23\"], df[\"PERWT23F\"], p)\n",
    "    \n",
    "    # Sample Share (Unweighted)\n",
    "    sample_share = (df[df[\"TOTSLF23\"] >= sample_threshold][\"TOTSLF23\"].sum() / sample_total_costs) * 100\n",
    "    \n",
    "    # Population Share (Weighted)\n",
    "    pop_share = (df[df[\"TOTSLF23\"] >= pop_threshold][\"pop_costs\"].sum() / pop_total_costs) * 100\n",
    "    \n",
    "    stats.append({\n",
    "        \"Top X%\": f\"Top {(1-p)*100:.0f}%\",\n",
    "        \"Threshold (Sample)\": sample_threshold,\n",
    "        \"Threshold (Population)\": pop_threshold,\n",
    "        \"Share of Total Costs (Sample)\": sample_share,\n",
    "        \"Share of Total Costs (Population)\": pop_share\n",
    "    })\n",
    "\n",
    "# Set \"Top X%\" as DataFrame index\n",
    "cost_concentration_df = pd.DataFrame(stats).set_index(\"Top X%\")\n",
    "\n",
    "# Show table with formatted values\n",
    "cost_concentration_df.style.format({\n",
    "    \"Threshold (Sample)\": \"${:,.0f}\",\n",
    "    \"Threshold (Population)\": \"${:,.0f}\",\n",
    "    \"Share of Total Costs (Sample)\": \"{:.1f}%\",\n",
    "    \"Share of Total Costs (Population)\": \"{:.1f}%\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd6ca97-604a-4728-8d01-2a0d607a2115",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Lorenz Curve</strong> <br>\n",
    "    üìå Plot the Lorenz Curve. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f21edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lorenz Curve\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Sort costs from lowest to highest\n",
    "sorted_costs = df[\"TOTSLF23\"].sort_values()\n",
    "\n",
    "# Calculate cumulative percentage of population and costs\n",
    "cum_pop = np.arange(1, len(sorted_costs) + 1) / len(sorted_costs) * 100\n",
    "cum_costs = sorted_costs.cumsum() / sorted_costs.sum() * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# The Lorenz Curve\n",
    "plt.plot(cum_pop, cum_costs, label=\"Lorenz Curve (Actual Costs)\", color=\"#084594\", lw=2)\n",
    "\n",
    "# The Line of Equality (Perfectly equal spend)\n",
    "plt.plot([0, 100], [0, 100], linestyle=\"--\", color=\"gray\", label=\"Line of Equality\")\n",
    "\n",
    "# Fill the area for visual emphasis\n",
    "plt.fill_between(cum_pop, cum_costs, cum_pop, color=\"#084594\", alpha=0.1)\n",
    "\n",
    "# Customization\n",
    "plt.title(\"Lorenz Curve: Concentration of Out-of-Pocket Costs\")\n",
    "plt.xlabel(\"Cumulative % of Population (Ordered from Lowest to Highest Costs)\")\n",
    "plt.ylabel(\"Cumulative % of Total Costs\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 101, 10))  # set grid lines every 10%\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter())  # format axis tick labels as percentages\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a087fc-cbca-4224-a3a9-f3a86f8a266a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f7fff8; padding:15px; border:3px solid #e0f0e0; border-radius:6px;\">\n",
    "    üí° <b>Insight:</b> High inequality in out-of-pocket health care spending.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>Top 1% Concentration:</b> The top 1% of respondents account for 20% of total out-of-pocket costs.</li>\n",
    "        <li><b>The 80/20 Rule:</b> The top 20% of respondents account for roughly 80% of total costs.</li>\n",
    "        <li><b>Zero Costs:</b> 21% of respondents have $0 in out-of-pocket costs.</li>\n",
    "        <li><b>Bottom 50%:</b> The bottom half of the population collectively accounts for less than 5% of total costs.</li>\n",
    "    </ul>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Medical Cost Prediction",
   "language": "python",
   "name": "medical_cost_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
