{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c0fc97-03a1-4567-afc2-bc1c009f58ee",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; font-size:36px; font-weight:bold; color:#4A4A4A; background-color:#fff6e4; padding:10px; border:3px solid #f5ecda; border-radius:6px\">\n",
    "    Medical Cost Prediction\n",
    "    <p style=\"text-align:center; font-size:14px; font-weight:normal; color:#4A4A4A; margin-top:12px;\">\n",
    "        Author: Jens Bender <br> \n",
    "        Created: December 2025<br>\n",
    "        Last updated: January 2026\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb46ade-5325-4a6f-a876-a89fa84ff886",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Imports</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fb71d4-23c3-4427-83da-a9f1b304504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data preprocessing (Scikit-learn)\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, \n",
    "    OneHotEncoder, \n",
    "    OrdinalEncoder\n",
    ")\n",
    "\n",
    "# Model selection\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform  # for random hyperparameter values\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor \n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, \n",
    "    mean_absolute_percentage_error, \n",
    "    r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ff7f1-cfe6-4266-9598-f8fa77825c29",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Data Loading and Inspection</h1>\n",
    "</div>\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Load the MEPS-HC 2023 data from the <code>h251.sas7bdat</code> file (SAS V9 format) into a Pandas DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566250d-933c-4ee9-950f-80f916b616b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load data using 'latin1' encoding because MEPS SAS files don't store text as UTF-8 and instead use Western European (ISO-8859-1), also known as latin1.\n",
    "    df = pd.read_sas(\"../data/h251.sas7bdat\", format=\"sas7bdat\", encoding=\"latin1\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: The file content could not be parsed.\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied when accessing the file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bd5af1-3289-4fd7-8ccd-f9d9b49bc884",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> üìå Initial data inspection to understand the structure of the dataset and detect obvious issues.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723eebff-80f4-4e7e-9e94-6af8816a1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame info to check the number of rows and columns, data types and missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a985d-3c7e-492f-9f34-a17df4f2c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top five rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06f785-b1fe-45ee-bfb2-224cb1235bf1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Data Preprocessing</h1>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Note</strong>: Kept column names in ALL CAPS in this project to ensure consistency with official <b><a href=\"../docs/references/h251doc.pdf\">MEPS documentation</a></b>, <b><a href=\"../docs/references/h251cb.pdf\">codebook</a></b>, and <b><a href=\"../docs/references/data_dictionary.md\">data dictionary</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5bc54-6ee9-4419-8811-86799d1874f0",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Handling Duplicates</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Identify duplicates based on:\n",
    "<ul>\n",
    "    <li><strong>All columns</strong>: To detect exactly identical rows.</li>\n",
    "    <li><strong>ID column only</strong>: To ensure that no two people share the same ID.</li>\n",
    "    <li><strong>All columns except ID</strong>: To catch \"hidden\" duplicates where the same respondent may have been recorded twice under different IDs.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6bf46-8cf6-4991-bea4-c2b167ff91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on all columns\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f382f-e7d9-46c3-b43a-5e6b5f8eb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on the ID column\n",
    "df.duplicated([\"DUPERSID\"]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07847cb-f83b-405f-b585-24f953c1cb6b",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ‚úÖ No duplicates were found based on all columns or the ID column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e58b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicates based on all columns except ID columns\n",
    "id_columns = [\"DUPERSID\", \"DUID\", \"PID\", \"PANEL\"]\n",
    "duplicates_without_id = df.duplicated(subset=df.columns.drop(id_columns), keep=False)\n",
    "duplicates_without_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360131b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show duplicates\n",
    "df[duplicates_without_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a4d05-0800-486e-9802-7b438182e952",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "    üí° There are 3 pairs (or 6 rows) of duplicates that have identical values across all 1,300+ columns except for their IDs. Analysis shows these are young siblings (ages 1 and 5) living in the same household with identical parent-reported health data, identical sample weights, and identical costs. Thus, they appear to be valid respondents rather than \"ghost records\". However, they will be naturally excluded when filtering for the adult target population.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19272d24-c56d-4a19-9ffc-dfd82d02fff1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Variable Selection</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Filter the following 29 columns (out of 1,374):\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>ID</b>: Unique identifier for each respondent (<code>DUPERSID</code>).</li>\n",
    "        <li><b>Sample Weights</b>: Ensures population representativeness (<code>PERWT23F</code>).</li>\n",
    "        <li><b>Candidate Features</b>: 26 variables selected for their consumer accessibility, beginning-of-year measurement, and predictive power.</li> \n",
    "        <li><b>Target Variable</b>: Total out-of-pocket health care costs (<code>TOTSLF23</code>).</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <b>Rationale</b>: For a detailed breakdown of the target variable selection and feature selection criteria, see the <b><a href=\"../docs/specs/technical_specifications.md\">Technical Specifications</a></b> and <b><a href=\"../docs/research/candidate_features.md\">Candidate Features Research</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep \n",
    "columns_to_keep = [\n",
    "    # 1. ID\n",
    "    \"DUPERSID\",\n",
    "    \n",
    "    # 2. Sample Weights\n",
    "    \"PERWT23F\", \n",
    "\n",
    "    # 3 Candidate Features.\n",
    "    # 3.1 Demographics\n",
    "    \"AGE23X\", \"SEX\", \"REGION23\", \"MARRY31X\",\n",
    "    \n",
    "    # 3.2 Socioeconomic\n",
    "    \"POVCAT23\", \"FAMSZE23\", \"HIDEG\", \"EMPST31\",\n",
    "    \n",
    "    # 3.3 Insurance & Access\n",
    "    \"INSCOV23\", \"HAVEUS42\",\n",
    "    \n",
    "    # 3.4 Perceived Health & Lifestyle\n",
    "    \"RTHLTH31\", \"MNHLTH31\", \"ADSMOK42\",\n",
    "    \n",
    "    # 3.5 Limitations & Symptoms\n",
    "    \"ADLHLP31\", \"IADLHP31\", \"WLKLIM31\", \"COGLIM31\", \"JTPAIN31_M18\",\n",
    "    \n",
    "    # 3.6 Chronic Conditions\n",
    "    \"HIBPDX\", \"CHOLDX\", \"DIABDX_M18\", \"CHDDX\", \"STRKDX\", \"CANCERDX\", \"ARTHDX\", \"ASTHDX\", \n",
    "    \n",
    "    # 4. Healthcare Expenditure (Target)\n",
    "    \"TOTSLF23\"\n",
    "]\n",
    "\n",
    "# Drop all other columns (keeping 29 out of 1,374)\n",
    "df = df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab17d4-5459-46b5-b864-3e992c45e4c8",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Filtering Target Population</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Filter rows to match the target population based on the following criteria:\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>Positive person weight</b> (<code>PERWT23F > 0</code>): Drop respondents with a person weight of zero (i.e., 456 respondents). These individuals are considered \"out-of-scope\" for the full-year population (e.g., they joined the military, were institutionalized, or moved abroad).</li>\n",
    "        <li><b>Adults</b> (<code>AGE23X >= 18</code>): Drop respondents under age 18 (i.e., 3796 respondents), as the medical cost planner app targets adults.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    <b>Note</b>: Keeps 14,768 out of 18,919 respondents.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80beb46-f9cf-4fc3-a80e-dee328f07f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame \n",
    "df = df[(df[\"PERWT23F\"] > 0) & (df[\"AGE23X\"] >= 18)].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b1bd90-9e04-432f-bb46-ef10b0530f31",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Handling Data Types</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå Identify and convert incorrect storage data types.\n",
    "    <ul>\n",
    "        <li><b>ID</b>: <code>DUPERSID</code> is an identifier, not a quantity. Converting them to <code>string</code> prevents unintended math.</li>\n",
    "        <li><b>Sample Weights</b>: <code>PERWT23F</code> contains decimal precision critical for population-level estimates. Must remain <code>float</code>.</li>\n",
    "        <li><b>Candidate Features</b>: The SAS loader stored all 26 features as floats by default. Although many features are categorical and represent integer codes (e.g., 1=Male, 2=Female), they are maintained as <code>float</code> for three practical reasons:\n",
    "            <ul>\n",
    "                <li>Missing Value Compatibility: In standard Pandas, <code>np.nan</code> is a floating-point object. Assigning it to an integer column automatically casts back to <code>float64</code>.</li>\n",
    "                <li>Data Preprocessing Consistency: scikit-learn transformers (e.g., <code>SimpleImputer</code>, <code>StandardScaler</code>) internally use floats and automatically convert numerical inputs to <code>float</code>, even when using <code>set_config(transform_output=\"pandas\")</code>. Keeping them as floats avoids redundant type casting.</li>\n",
    "                <li>Model Consistency: Most machine learning models (e.g., XGBoost, Linear Regression) internally use floats and automatically convert numerical inputs to <code>float</code> during training and inference. Keeping them as floats avoids redundant type casting.</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><b>Target Variable</b>: <code>TOTSLF23</code> is rounded to whole dollars in the raw MEPS data. It is kept as <code>float</code> for Model Consistency and to avoid redundant type casting, as ML models deliver <code>float</code> predictions during training and inference.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b59357-2082-44a7-9862-589ccd104e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify storage data types (defaulted to float/object by SAS loader)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca8040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ID to string\n",
    "df[\"DUPERSID\"] = df[\"DUPERSID\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c1c55-f1a7-4322-8f2b-d0e4475d767d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Standardizing Missing Values</h1>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è <b>Pandas Missing Value Types</b>:\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>np.nan</b>: Standard missing value indicator (technically a float); often the default in Pandas for numerical data.</li>\n",
    "        <li><b>pd.NA</b>: Unified missing value indicator for modern nullable data types (mostly integer and boolean).</li>\n",
    "        <li><b>None</b>: Python's native type; often used for object and string data.</li>\n",
    "        <li><b>pd.NaT</b>: For datetime and timedelta data types.</li>\n",
    "    </ul>\n",
    "    <br>\n",
    "    ‚ÑπÔ∏è <b>MEPS Missing Value Codes</b>:\n",
    "    <ul style=\"margin-bottom:0px\">\n",
    "        <li><b>-1 INAPPLICABLE</b>: Variable does not apply (structural skip).</li>\n",
    "        <li><b>-7 REFUSED</b>: Person refused to answer.</li>\n",
    "        <li><b>-8 DON'T KNOW</b>: Person did not know the answer.</li>\n",
    "        <li><b>-9 NOT ASCERTAINED</b>: Administrative or technical error in collection.</li>\n",
    "        <li><b>-15 CANNOT BE COMPUTED</b>: Incomplete data for a constructed variable.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf771bde-99a8-4618-8c2d-82de58a9a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Pandas missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4fd4f1",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    üìå <b>Handle MEPS-Specific Missing Values and Skip Patterns</b>\n",
    "    <br><br>\n",
    "    <b>Understanding Skip Patterns</b><br>\n",
    "    Skip patterns (routing logic) are used in surveys to ensure respondents only answer questions relevant to them, reducing burden and improving data quality. For analysis, this creates \"structural\" missingness (coded as -1 Inapplicable) can often be recovered by looking at the respondent's path through the survey.\n",
    "    <br><br>\n",
    "    <b>Recovering Implied Values:</b>  \n",
    "    <ul>\n",
    "        <li><b>Smoker</b> (<code>ADSMOK42</code>): This question is only asked if the respondent already confirmed smoking 100+ cigarettes in their life. Those who said \"No\" skip this and are coded -1. In this project, these \"Never Smokers\" are mapped to \"No\" (2).</li>\n",
    "        <li><b>Joint Pain</b> (<code>JTPAIN31_M18</code>): Respondents who already reported an arthritis diagnosis (<code>ARTHDX = 1</code>) earlier in the interview skip this question and are coded -1. Since arthritis inherently involves joint symptoms, these values are mapped to \"Yes\" (1).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae9015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover implied values\n",
    "# Smoker: Convert -1 (Never Smoker) to 2 (No)\n",
    "df.loc[df[\"ADSMOK42\"] == -1, \"ADSMOK42\"] = 2\n",
    "\n",
    "# Joint Pain: Convert -1 to 1 (Yes) only if they have Arthritis \n",
    "df.loc[(df[\"JTPAIN31_M18\"] == -1) & (df[\"ARTHDX\"] == 1), \"JTPAIN31_M18\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45ca1e-7a62-4ee5-9815-47a528cae451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify MEPS missing values \n",
    "missing_codes = [-1, -7, -8, -9, -15]\n",
    "missing_frequency_df = pd.DataFrame({code: (df == code).sum() for code in missing_codes})\n",
    "missing_frequency_df[\"TOTAL\"] = missing_frequency_df.sum(axis=1)\n",
    "missing_frequency_df[\"PERCENTAGE\"] = (missing_frequency_df[\"TOTAL\"] / len(df) * 100).round(2)\n",
    "missing_frequency_df.sort_values(\"TOTAL\", ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82708ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all MEPS missing codes to np.nan\n",
    "df = df.replace(missing_codes, np.nan)\n",
    "\n",
    "# Verify results\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2413d70-ad80-4f97-af40-0f1e56a10b78",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Train-Validation-Test Split</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "    üìå Split the data into 80% for training, 10% for validation, and 10% for testing.\n",
    "    <table style=\"margin-left:0; margin-top:20px; margin-bottom:20px\">\n",
    "        <tr>\n",
    "            <th style=\"background-color:#f5ecda;\">Data</th>\n",
    "            <th style=\"background-color:#f5ecda;\">Size (%)</th>\n",
    "            <th style=\"background-color:#f5ecda;\">Size (Total)</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#fff6e4;\">Training Set</td>\n",
    "            <td style=\"background-color:#fff6e4;\">80%</td>\n",
    "            <td style=\"background-color:#fff6e4;\">11,814</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#f5ecda;\">Validation Set</td>\n",
    "            <td style=\"background-color:#f5ecda;\">10%</td>\n",
    "            <td style=\"background-color:#f5ecda;\">1,477</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"background-color:#fff6e4;\">Test Set</td>\n",
    "            <td style=\"background-color:#fff6e4;\">10%</td>\n",
    "            <td style=\"background-color:#fff6e4;\">1,477</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a43bb6b-9495-40b6-9361-c679fbbf7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X features and y target\n",
    "X = df.drop(\"TOTSLF23\", axis=1)\n",
    "y = df[\"TOTSLF23\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b09251-1df0-4598-9da1-70ae4d6307bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and temporary sets (80% train, 20% temporary)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary data into validation and test sets (50% each)\n",
    "# Note: This accomplishes a 80% training, 10% validation and 10% test set size\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Delete the temporary data to free up memory\n",
    "del X_temp, y_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c355c2-6e31-44b4-942a-9809fa990ded",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#2c699d; color:white; padding:15px; border-radius:6px;\">\n",
    "    <h1 style=\"margin:0px\">Exploratory Data Analysis (EDA)</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ede20-f3f6-4774-8c25-54b6feb8333e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#3d7ab3; color:white; padding:12px; border-radius:6px;\">\n",
    "    <h2 style=\"margin:0px\">Univariate EDA</h2>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è Analyze the distribution of a single column using descriptive statistics and visualizations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ccbccf-4f44-4781-bbd3-702244b2b93a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#4e8ac8; color:white; padding:10px; border-radius:6px;\">\n",
    "    <h3 style=\"margin:0px\">Numerical Columns</h3>\n",
    "</div> \n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border:3px solid #d0e7fa; border-radius:6px;\">\n",
    "    ‚ÑπÔ∏è Examine descriptive statistics (e.g., mean, median, standard deviation) and visualize the distributions (e.g., histograms) of numerical columns.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc6827-8945-406c-87e1-9c87b9273d40",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Descriptive Statistics</strong> <br>\n",
    "    üìå Examine descriptive statistics of out-of-pocket costs (target variable). \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669b0f46-4070-4f01-ae04-4ace055a97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of target variable\n",
    "df[\"TOTSLF23\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9427d8e-502b-4502-9f54-640ea64f1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero costs\n",
    "zero_costs_summary = pd.DataFrame({\n",
    "    \"Count\": [(df[\"TOTSLF23\"] == 0).sum(), (df[\"TOTSLF23\"] > 0).sum()],\n",
    "    \"Percentage\": [\n",
    "        (df[\"TOTSLF23\"] == 0).mean() * 100,\n",
    "        (df[\"TOTSLF23\"] > 0).mean() * 100\n",
    "    ]\n",
    "}, index=[\"Zero Costs\", \"Positive Costs\"]).round(2)\n",
    "zero_costs_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b218849-3849-4c3d-9f24-cc07d5615a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 1% costs\n",
    "top_1_cutoff = df[\"TOTSLF23\"].quantile(0.99)\n",
    "top_1_sum = df[df[\"TOTSLF23\"] > top_1_cutoff][\"TOTSLF23\"].sum()\n",
    "bottom_99_sum = df[df[\"TOTSLF23\"] <= top_1_cutoff][\"TOTSLF23\"].sum()\n",
    "top_1_share = top_1_sum / (top_1_sum + bottom_99_sum) * 100\n",
    "\n",
    "print(f\"The top 1% starts at: ${top_1_cutoff:,.0f}\")\n",
    "print(f\"The top 1% have summed costs of: ${top_1_sum / 1_000_000:.1f}M\")\n",
    "print(f\"The bottom 99% have summed costs of: ${bottom_99_sum / 1_000_000:.1f}M\")\n",
    "print(f\"The top 1% of respondents account for {top_1_share:.0f}% of total out-of-pocket costs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfdff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concentration of Out-of-Pocket Costs\n",
    "percentiles = [0.99, 0.95, 0.9, 0.8, 0.5]\n",
    "stats = []\n",
    "total_spend = df[\"TOTSLF23\"].sum()\n",
    "for p in percentiles:\n",
    "    cutoff = df[\"TOTSLF23\"].quantile(p)\n",
    "    spend_above = df[df[\"TOTSLF23\"] > cutoff][\"TOTSLF23\"].sum()\n",
    "    share = (spend_above / total_spend) * 100\n",
    "    stats.append({\n",
    "        \"Top X%\": f\"Top {(1-p)*100:.0f}%\",\n",
    "        \"Cutoff\": f\"${cutoff:,.0f}\",\n",
    "        \"Share of Total Costs\": f\"{share:.0f}%\"\n",
    "    })\n",
    "concentration_df = pd.DataFrame(stats)\n",
    "concentration_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f21edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lorenz Curve\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Sort costs from lowest to highest\n",
    "sorted_costs = df[\"TOTSLF23\"].sort_values()\n",
    "\n",
    "# Calculate cumulative percentage of population and costs\n",
    "cum_pop = np.arange(1, len(sorted_costs) + 1) / len(sorted_costs) * 100\n",
    "cum_costs = sorted_costs.cumsum() / sorted_costs.sum() * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# The Lorenz Curve\n",
    "plt.plot(cum_pop, cum_costs, label=\"Lorenz Curve (Actual Costs)\", color=\"#084594\", lw=2)\n",
    "\n",
    "# The Line of Equality (Perfectly equal spend)\n",
    "plt.plot([0, 100], [0, 100], linestyle=\"--\", color=\"gray\", label=\"Line of Equality\")\n",
    "\n",
    "# Fill the area for visual emphasis\n",
    "plt.fill_between(cum_pop, cum_costs, cum_pop, color=\"#084594\", alpha=0.1)\n",
    "\n",
    "# Customization\n",
    "plt.title(\"Lorenz Curve: Concentration of Out-of-Pocket Costs\")\n",
    "plt.xlabel(\"Cumulative % of Population (Ordered from Lowest to Highest Costs)\")\n",
    "plt.ylabel(\"Cumulative % of Total Costs\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(range(0, 101, 10))  # set grid lines every 10%\n",
    "plt.yticks(range(0, 101, 10))\n",
    "plt.gca().xaxis.set_major_formatter(mtick.PercentFormatter())  # format axis tick labels as percentages\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a087fc-cbca-4224-a3a9-f3a86f8a266a",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\">\n",
    "    üí° <b>Insight</b>: High inequality in out-of-pocket health care spending.\n",
    "    <ul style=\"margin-top:10px; margin-bottom:0px\">\n",
    "        <li><b>Top 1% Concentration</b>: The top 1% of respondents account for 20% of total out-of-pocket costs.</li>\n",
    "        <li><b>The 80/20 Rule</b>: The top 20% of respondents account for roughly 80% of total costs.</li>\n",
    "        <li><b>Zero Costs</b>: 21% of respondents have $0 in out-of-pocket costs.</li>\n",
    "        <li><b>Bottom 50%</b>: The bottom half of the population collectively accounts for less than 5% of total costs.</li>\n",
    "    </ul>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e54d1bc-fca3-4581-bdb5-767b1c70117d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6e4; padding:15px; border:3px solid #f5ecda; border-radius:6px;\">\n",
    "    <strong>Visualize Distributions</strong> <br> \n",
    "    üìå Histogram that shows the distribution of the target variable. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b997595-aa23-4a3a-b784-02585eea7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of out-of-pocket costs\n",
    "sns.histplot(df[\"TOTSLF23\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e34f5b-8a58-43a4-a335-182949e995ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogram of out-of-pocket costs excluding zero costs and top 1% \n",
    "sns.histplot(df[(df[\"TOTSLF23\"] > 0) & (df[\"TOTSLF23\"] <= top_1_cutoff)][\"TOTSLF23\"])"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Medical Cost Prediction",
   "language": "python",
   "name": "medical_cost_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
